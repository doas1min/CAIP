{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaaO38T7sI6q"
   },
   "source": [
    "### 주의 : 본 코드는 책에 대한 학습 및 교육외에 배포를 금지합니다.\n",
    "### Warning: This code is prohibited from distribution except for learning and educational purposes related to the book.\n",
    "4장 딥러닝을 활용한 화학특성분석\n",
    "- by Keunhong Jeong\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHyZr85XIh21"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/doas1min/CAIP/main/data/Lipophilicity_G2.csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "# 파일을 저장합니다.\n",
    "with open('Lipophilicity_test.csv', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 읽기\n",
    "data = pd.read_csv('Lipophilicity_test.csv')\n",
    "\n",
    "# index 변경\n",
    "data.set_index(['smiles', 'logD'], inplace=True)\n",
    "data.index.names = ['SMILES', 'Lipophilicity']\n",
    "\n",
    "# CSV 파일로 저장\n",
    "data.to_csv('Lipophilicity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKqvGsuhI0Yc"
   },
   "outputs": [],
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PTIX0uxaIya2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"Lipophilicity.csv\")\n",
    "\n",
    "# SMILES -> Mol 변환 (파싱 실패 처리)\n",
    "data[\"Mol\"] = data[\"SMILES\"].apply(Chem.MolFromSmiles)\n",
    "print(\"파싱 실패 SMILES 개수 :\", data[\"Mol\"].isna().sum())\n",
    "data = data.dropna(subset=[\"Mol\"]).reset_index(drop=True)\n",
    "\n",
    "# Descriptor 추출\n",
    "data['TPSA'] = data['Mol'].apply(Descriptors.TPSA)\n",
    "data['LogP'] = data['Mol'].apply(Descriptors.MolLogP)\n",
    "data['MolecularWeight'] = data['Mol'].apply(Descriptors.MolWt)\n",
    "data['NumRotatableBonds'] = data['Mol'].apply(Descriptors.NumRotatableBonds)\n",
    "\n",
    "# 데이터 살펴보기\n",
    "print(data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds', 'Lipophilicity']].describe())\n",
    "\n",
    "# Descriptor에 대한 히스토그램\n",
    "data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds']].hist(\n",
    "    bins=30, figsize=(15, 10), layout=(2, 2)\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# 상관관계 분석\n",
    "sns.pairplot(data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds', 'Lipophilicity']])\n",
    "plt.show()\n",
    "\n",
    "# 입력 변수와 타겟 변수 분할\n",
    "X = data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds']]\n",
    "y = data['Lipophilicity']\n",
    "\n",
    "# 데이터 표준화\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# MLP 모델 학습\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=20\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 예측 성능 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error :\", mse)\n",
    "print(\"R^2 :\", r2)\n",
    "\n",
    "# 예측값 vs 실제값 분포 그래프\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, c='crimson', alpha=0.7)\n",
    "\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p2, p1], [p2, p1], 'b-')\n",
    "\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpdqwoneIy1u"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"Lipophilicity.csv\")\n",
    "\n",
    "# SMILES -> Mol 변환 (파싱 실패 처리)\n",
    "data[\"Mol\"] = data[\"SMILES\"].apply(Chem.MolFromSmiles)\n",
    "print(\"파싱 실패 SMILES 개수 :\", data[\"Mol\"].isna().sum())\n",
    "data = data.dropna(subset=[\"Mol\"]).reset_index(drop=True)\n",
    "\n",
    "# Morgan fingerprint generator 생성 (RDKit 권장 방식)\n",
    "morgan_gen = rdFingerprintGenerator.GetMorganGenerator(\n",
    "    radius=2,\n",
    "    fpSize=1024\n",
    ")\n",
    "\n",
    "# Morgan fingerprint 계산 함수\n",
    "def get_morgan_fingerprint(mol):\n",
    "    return np.array(morgan_gen.GetFingerprint(mol))\n",
    "\n",
    "# Descriptor 추출\n",
    "data[\"MorganFingerprint\"] = data[\"Mol\"].apply(get_morgan_fingerprint)\n",
    "\n",
    "# 입력 변수와 타겟 변수 분할\n",
    "X = np.vstack(data[\"MorganFingerprint\"].values)\n",
    "y = data[\"Lipophilicity\"].values\n",
    "\n",
    "# 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# MLP 모델 학습\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    early_stopping=True\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 예측 성능 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error :\", mse)\n",
    "print(\"R^2 :\", r2)\n",
    "\n",
    "# 예측값 vs 실제값 분포 그래프\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, c='crimson', alpha=0.7)\n",
    "\n",
    "p1 = max(max(y_pred), max(y_test))\n",
    "p2 = min(min(y_pred), min(y_test))\n",
    "plt.plot([p2, p1], [p2, p1], 'b-')\n",
    "\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJjmZaR6VloN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdFingerprintGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"Lipophilicity.csv\")\n",
    "\n",
    "# SMILES -> Mol 변환 (파싱 실패 처리)\n",
    "data[\"Mol\"] = data[\"SMILES\"].apply(Chem.MolFromSmiles)\n",
    "print(\"파싱 실패 SMILES 개수 :\", data[\"Mol\"].isna().sum())\n",
    "data = data.dropna(subset=[\"Mol\"]).reset_index(drop=True)\n",
    "\n",
    "# 기존 Descriptor 추출 (Mol 기반)\n",
    "data[\"TPSA\"] = data[\"Mol\"].apply(Descriptors.TPSA)\n",
    "data[\"LogP\"] = data[\"Mol\"].apply(Descriptors.MolLogP)\n",
    "data[\"MolecularWeight\"] = data[\"Mol\"].apply(Descriptors.MolWt)\n",
    "data[\"NumRotatableBonds\"] = data[\"Mol\"].apply(Descriptors.NumRotatableBonds)\n",
    "\n",
    "# Morgan fingerprint generator (권장 방식)\n",
    "morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024)\n",
    "\n",
    "# Morgan fingerprint 추출 (Mol 기반)\n",
    "data[\"MorganFingerprint\"] = data[\"Mol\"].apply(lambda m: np.array(morgan_gen.GetFingerprint(m)))\n",
    "\n",
    "# Morgan fingerprint를 bit 컬럼으로 펼치기\n",
    "morgan_df = pd.DataFrame(\n",
    "    data[\"MorganFingerprint\"].to_list(),\n",
    "    columns=[f\"bit{i}\" for i in range(1024)]\n",
    ")\n",
    "\n",
    "# 입력 변수 만들기 (Descriptor + Morgan bits)\n",
    "X = pd.concat(\n",
    "    [data[[\"TPSA\", \"LogP\", \"MolecularWeight\", \"NumRotatableBonds\"]], morgan_df],\n",
    "    axis=1\n",
    ")\n",
    "y = data[\"Lipophilicity\"].values\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 데이터 표준화 (train 기준)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# MLP 모델 학습\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    max_iter=2000,\n",
    "    random_state=42,\n",
    "    early_stopping=True\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 예측 성능 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error :\", mse)\n",
    "print(\"R^2 :\", r2)\n",
    "\n",
    "# 예측값 vs 실제값 분포 그래프 (log 스케일 제거: 음수 가능)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, y_pred, c='crimson', alpha=0.7)\n",
    "\n",
    "p1 = max(np.max(y_pred), np.max(y_test))\n",
    "p2 = min(np.min(y_pred), np.min(y_test))\n",
    "plt.plot([p2, p1], [p2, p1], 'b-')\n",
    "\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RcC_87Q6XeIk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, rdFingerprintGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Concatenate, Conv1D, GlobalAveragePooling1D\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"Lipophilicity.csv\")\n",
    "\n",
    "# SMILES -> Mol 변환 (파싱 실패 처리)\n",
    "data[\"Mol\"] = data[\"SMILES\"].apply(Chem.MolFromSmiles)\n",
    "print(\"파싱 실패 SMILES 개수 :\", data[\"Mol\"].isna().sum())\n",
    "data = data.dropna(subset=[\"Mol\"]).reset_index(drop=True)\n",
    "\n",
    "# 기존 Descriptor 추출 (Mol 기반)\n",
    "data[\"TPSA\"] = data[\"Mol\"].apply(Descriptors.TPSA)\n",
    "data[\"LogP\"] = data[\"Mol\"].apply(Descriptors.MolLogP)\n",
    "data[\"MolecularWeight\"] = data[\"Mol\"].apply(Descriptors.MolWt)\n",
    "data[\"NumRotatableBonds\"] = data[\"Mol\"].apply(Descriptors.NumRotatableBonds)\n",
    "\n",
    "# Morgan fingerprint generator (권장 방식)\n",
    "morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024)\n",
    "\n",
    "# MorganFingerprint 추출 (Mol 기반)\n",
    "data[\"MorganFingerprint\"] = data[\"Mol\"].apply(lambda m: np.array(morgan_gen.GetFingerprint(m), dtype=np.float32))\n",
    "\n",
    "# 입력 변수와 타겟 변수 분할\n",
    "X_global = data[[\"TPSA\", \"LogP\", \"MolecularWeight\", \"NumRotatableBonds\"]].values.astype(np.float32)\n",
    "X_fingerprint = np.stack(data[\"MorganFingerprint\"].values).astype(np.float32)\n",
    "y = data[\"Lipophilicity\"].values.astype(np.float32)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터 분할\n",
    "X_global_train, X_global_test, X_fingerprint_train, X_fingerprint_test, y_train, y_test = train_test_split(\n",
    "    X_global, X_fingerprint, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 데이터 표준화 (train 기준)\n",
    "scaler_global = StandardScaler()\n",
    "X_global_train = scaler_global.fit_transform(X_global_train).astype(np.float32)\n",
    "X_global_test = scaler_global.transform(X_global_test).astype(np.float32)\n",
    "\n",
    "scaler_fingerprint = StandardScaler()\n",
    "X_fingerprint_train = scaler_fingerprint.fit_transform(X_fingerprint_train).astype(np.float32)\n",
    "X_fingerprint_test = scaler_fingerprint.transform(X_fingerprint_test).astype(np.float32)\n",
    "\n",
    "# Conv1D 입력 형태로 차원 추가\n",
    "X_fingerprint_train = np.expand_dims(X_fingerprint_train, axis=2)\n",
    "X_fingerprint_test = np.expand_dims(X_fingerprint_test, axis=2)\n",
    "\n",
    "# 모델 구성\n",
    "input_global = Input(shape=(X_global_train.shape[1],), name=\"global_input\")\n",
    "input_fingerprint = Input(shape=(X_fingerprint_train.shape[1], 1), name=\"fingerprint_input\")\n",
    "\n",
    "conv1 = Conv1D(16, 3, activation=\"relu\")(input_fingerprint)\n",
    "gap1 = GlobalAveragePooling1D()(conv1)\n",
    "\n",
    "concat = Concatenate()([input_global, gap1])\n",
    "\n",
    "dense1 = Dense(64, activation=\"relu\")(concat)\n",
    "output = Dense(1)(dense1)\n",
    "\n",
    "model = Model(inputs=[input_global, input_fingerprint], outputs=output)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# 모델 구조 시각화\n",
    "plot_model(model, to_file=\"model_plot.png\", show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    [X_global_train, X_fingerprint_train],\n",
    "    y_train,\n",
    "    validation_data=([X_global_test, X_fingerprint_test], y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 모델 학습 과정 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델 평가\n",
    "loss = model.evaluate([X_global_test, X_fingerprint_test], y_test, verbose=0)\n",
    "print(\"Test Loss:\", loss)\n",
    "\n",
    "# 예측값 계산\n",
    "y_pred = model.predict([X_global_test, X_fingerprint_test]).reshape(-1)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "# 예측값과 실제값 비교 시각화 (log scale 제거)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(y_test, y_pred, c=\"crimson\", alpha=0.7)\n",
    "\n",
    "p1 = max(np.max(y_pred), np.max(y_test))\n",
    "p2 = min(np.min(y_pred), np.min(y_test))\n",
    "plt.plot([p2, p1], [p2, p1], \"b-\")\n",
    "\n",
    "plt.xlabel(\"True Values\", fontsize=15)\n",
    "plt.ylabel(\"Predictions\", fontsize=15)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SK7rD8vecxO1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Input, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"Lipophilicity.csv\")\n",
    "\n",
    "# SMILES 문자열을 추출\n",
    "smiles_list = data[\"SMILES\"].astype(str).values.tolist()\n",
    "\n",
    "# SMILES 문자열을 토큰화하고 정수 인코딩\n",
    "tokenizer = Tokenizer(char_level=True, lower=False, filters=\"\")\n",
    "tokenizer.fit_on_texts(smiles_list)\n",
    "sequences = tokenizer.texts_to_sequences(smiles_list)\n",
    "\n",
    "# 시퀀스 패딩\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "X_smiles = pad_sequences(sequences, maxlen=max_length, padding=\"post\")\n",
    "\n",
    "# Lipophilicity를 타겟 변수로 설정\n",
    "y = data[\"Lipophilicity\"].values.astype(np.float32)\n",
    "\n",
    "# 트레이닝셋과 테스트셋 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_smiles, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# RNN 모델 구성 (원-핫 대신 Embedding 사용)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "embed = Embedding(input_dim=vocab_size, output_dim=32, mask_zero=True)(input_layer)\n",
    "\n",
    "lstm_layer1 = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.0)(embed)\n",
    "lstm_layer2 = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.0)(lstm_layer1)\n",
    "lstm_layer3 = LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.0)(lstm_layer2)\n",
    "\n",
    "output_layer = Dense(1, activation=\"linear\")(lstm_layer3)\n",
    "\n",
    "# 모델 컴파일\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(), loss=\"mean_squared_error\")\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# 테스트셋에 대한 예측 수행\n",
    "y_pred = model.predict(X_test).reshape(-1)\n",
    "\n",
    "# 예측 결과 평가 (Mean Squared Error와 R2 Score)\n",
    "mse = mean_squared_e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HqrGoVKCx-DY"
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5U7S25Knd4yX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(\"Lipophilicity.csv\")\n",
    "\n",
    "# SMILES -> Mol 변환 (파싱 실패 처리)\n",
    "df[\"Mol\"] = df[\"SMILES\"].apply(Chem.MolFromSmiles)\n",
    "print(\"파싱 실패 SMILES 개수 :\", df[\"Mol\"].isna().sum())\n",
    "df = df.dropna(subset=[\"Mol\"]).reset_index(drop=True)\n",
    "\n",
    "# rdkit Mol -> PyG Data 변환\n",
    "def mol_to_data(mol, y_value):\n",
    "    x = torch.tensor([[atom.GetAtomicNum()] for atom in mol.GetAtoms()], dtype=torch.float)\n",
    "\n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edges.append([i, j])\n",
    "        edges.append([j, i])\n",
    "\n",
    "    if len(edges) == 0:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "    else:\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    y = torch.tensor([y_value], dtype=torch.float)\n",
    "    return Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# 그래프 데이터셋 만들기\n",
    "dataset = [\n",
    "    mol_to_data(mol, y_val)\n",
    "    for mol, y_val in zip(df[\"Mol\"].values, df[\"Lipophilicity\"].values)\n",
    "]\n",
    "\n",
    "# 트레이닝셋과 테스트셋 분리\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 그래프 신경망(GNN) 모델 구성\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(1, 64)\n",
    "        self.conv2 = GCNConv(64, 64)\n",
    "        self.conv3 = GCNConv(64, 64)\n",
    "        self.fc = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = GNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# 학습\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(batch)              # (batch_size,)\n",
    "        target = batch.y.view(-1)          # (batch_size,)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        test_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch = batch.to(device)\n",
    "                output = model(batch)\n",
    "                target = batch.y.view(-1)\n",
    "                loss = criterion(output, target)\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(\"Train Loss:\", np.mean(train_losses))\n",
    "        print(\"Test Loss:\", np.mean(test_losses))\n",
    "\n",
    "# 평가\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        output = model(batch).cpu().numpy().flatten()\n",
    "        target = batch.y.view(-1).cpu().numpy().flatten()\n",
    "        y_pred.append(output)\n",
    "        y_true.append(target)\n",
    "\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "print(\"MSE: \", mean_squared_error(y_true, y_pred))\n",
    "print(\"R2 score: \", r2_score(y_true, y_pred))\n",
    "\n",
    "# 결과 시각화 (log scale 제거)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_true, y_pred, c=\"crimson\", alpha=0.7)\n",
    "\n",
    "p1 = max(np.max(y_pred), np.max(y_true))\n",
    "p2 = min(np.min(y_pred), np.min(y_true))\n",
    "plt.plot([p2, p1], [p2, p1], \"b-\")\n",
    "\n",
    "plt.xlabel(\"True Values\", fontsize=15)\n",
    "plt.ylabel(\"Predictions\", fontsize=15)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJ-QBrczx6Hd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader  # 변경: deprecated 해결\n",
    "from torch_geometric.nn import global_mean_pool, GATConv\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv('Lipophilicity.csv')\n",
    "\n",
    "# SMILES -> Mol 변환 (파싱 실패 처리)\n",
    "data[\"Mol\"] = data[\"SMILES\"].apply(Chem.MolFromSmiles)\n",
    "print(\"파싱 실패 SMILES 개수 :\", data[\"Mol\"].isna().sum())\n",
    "data = data.dropna(subset=[\"Mol\"]).reset_index(drop=True)\n",
    "\n",
    "# 원자와 결합의 최대 개수 설정\n",
    "max_atoms = max([mol.GetNumAtoms() for mol in data[\"Mol\"]])\n",
    "\n",
    "def smiles_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    adj = Chem.rdmolops.GetAdjacencyMatrix(mol)\n",
    "    features = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
    "\n",
    "    # 패딩 수행\n",
    "    n_atoms = len(features)\n",
    "    features.extend([0] * (max_atoms - n_atoms))\n",
    "    adj_padding = np.zeros((max_atoms, max_atoms))\n",
    "    adj_padding[:n_atoms, :n_atoms] = adj\n",
    "\n",
    "    return adj_padding, features\n",
    "\n",
    "graphs = [smiles_to_graph(smiles) for smiles in data['SMILES']]\n",
    "X = [torch.tensor(features, dtype=torch.float).view(-1, 1) for _, features in graphs]\n",
    "A = [torch.tensor(adj, dtype=torch.long) for adj, _ in graphs]\n",
    "y = torch.tensor(data['Lipophilicity'].values, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "# 글로벌 특성 추가 (Mol 기반)\n",
    "data['TPSA'] = data['Mol'].apply(Descriptors.TPSA)\n",
    "data['LogP'] = data['Mol'].apply(Descriptors.MolLogP)\n",
    "data['MolecularWeight'] = data['Mol'].apply(Descriptors.MolWt)\n",
    "data['NumRotatableBonds'] = data['Mol'].apply(Descriptors.NumRotatableBonds)\n",
    "\n",
    "# 글로벌 특성 데이터를 텐서로 변환\n",
    "global_features = torch.tensor(\n",
    "    data[['TPSA', 'LogP', 'MolecularWeight','NumRotatableBonds']].values,\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, X, A, y, global_features):\n",
    "        self.X = X\n",
    "        self.A = A\n",
    "        self.y = y\n",
    "        self.global_features = global_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        edge_index, _ = dense_to_sparse(self.A[idx])\n",
    "        return Data(\n",
    "            x=self.X[idx],\n",
    "            edge_index=edge_index,\n",
    "            y=self.y[idx],\n",
    "            global_features=self.global_features[idx]  # 그대로 유지\n",
    "        )\n",
    "\n",
    "# 트레이닝셋과 테스트셋 분리\n",
    "X_train, X_test, A_train, A_test, y_train, y_test, global_train, global_test = train_test_split(\n",
    "    X, A, y, global_features, test_size=0.2, random_state=42\n",
    ")\n",
    "train_data = GraphDataset(X_train, A_train, y_train, global_train)\n",
    "test_data = GraphDataset(X_test, A_test, y_test, global_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# 그래프 신경망(GAT) 모델 구성\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GATConv(1, 64)\n",
    "        self.conv2 = GATConv(64, 64)\n",
    "        self.conv3 = GATConv(64, 64)\n",
    "        self.global_feature_layer = Linear(4, 64)\n",
    "        self.fc = Linear(128, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, global_features = data.x, data.edge_index, data.global_features\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "\n",
    "        global_features = global_features.view(-1, 4)  # 추가: 배치 후 shape 복원\n",
    "        global_features = self.global_feature_layer(global_features).relu()\n",
    "\n",
    "        x = torch.cat([x, global_features], dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x.view(-1)\n",
    "\n",
    "# 모델, 손실함수, 최적화 함수 설정\n",
    "model = GNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)\n",
    "\n",
    "# 학습\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        test_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                output = model(batch)\n",
    "                loss = criterion(output, batch.y.view(-1))\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        print(f'Epoch {epoch}:')\n",
    "        print('Train Loss:', np.mean(train_losses))\n",
    "        print('Test Loss:', np.mean(test_losses))\n",
    "        model.train()\n",
    "\n",
    "# 평가\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        output = model(batch)\n",
    "        y_pred.append(output.detach().numpy().flatten())\n",
    "        y_true.append(batch.y.view(-1).numpy().flatten())\n",
    "\n",
    "y_pred = np.concatenate(y_pred)\n",
    "y_true = np.concatenate(y_true)\n",
    "\n",
    "print('MSE: ', mean_squared_error(y_true, y_pred))\n",
    "print('R2 score: ', r2_score(y_true, y_pred))\n",
    "\n",
    "# 결과 시각화 (log scale 제거)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_true, y_pred, c='crimson', alpha=0.7)\n",
    "\n",
    "p1 = max(np.max(y_pred), np.max(y_true))\n",
    "p2 = min(np.min(y_pred), np.min(y_true))\n",
    "plt.plot([p2, p1], [p2, p1], 'b-')\n",
    "\n",
    "plt.xlabel('True Values', fontsize=15)\n",
    "plt.ylabel('Predictions', fontsize=15)\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFTqXxoi45lq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
