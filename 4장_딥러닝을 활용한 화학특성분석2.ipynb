{"cells":[{"cell_type":"markdown","metadata":{"id":"OaaO38T7sI6q"},"source":["### 주의 : 본 코드는 책에 대한 학습 및 교육외에 배포를 금지합니다.\n","### Warning: This code is prohibited from distribution except for learning and educational purposes related to the book.\n","4장 딥러닝을 활용한 화학특성분석\n","- by Keunhong Jeong\n","\n","![image.png](attachment:image.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LHyZr85XIh21"},"outputs":[],"source":["import requests\n","\n","url = 'https://raw.githubusercontent.com/doas1min/CAIP/main/data/Lipophilicity_G2.csv'\n","response = requests.get(url)\n","\n","# 파일을 저장합니다.\n","with open('Lipophilicity_test.csv', 'wb') as f:\n","    f.write(response.content)\n","\n","import pandas as pd\n","\n","# CSV 파일 읽기\n","data = pd.read_csv('Lipophilicity_test.csv')\n","\n","# index 변경\n","data.set_index(['smiles', 'logD'], inplace=True)\n","data.index.names = ['SMILES', 'Lipophilicity']\n","\n","# CSV 파일로 저장\n","data.to_csv('Lipophilicity.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKqvGsuhI0Yc"},"outputs":[],"source":["!pip install rdkit==2023.03.01"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PTIX0uxaIya2"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import Descriptors\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 데이터 불러오기\n","data = pd.read_csv(\"Lipophilicity.csv\")\n","\n","# Descriptor 추출\n","data['TPSA'] = data['SMILES'].apply(lambda x: Descriptors.TPSA(Chem.MolFromSmiles(x)))\n","data['LogP'] = data['SMILES'].apply(lambda x: Descriptors.MolLogP(Chem.MolFromSmiles(x)))\n","data['MolecularWeight'] = data['SMILES'].apply(lambda x: Descriptors.MolWt(Chem.MolFromSmiles(x)))\n","data['NumRotatableBonds'] = data['SMILES'].apply(lambda x: Descriptors.NumRotatableBonds(Chem.MolFromSmiles(x)))\n","\n","# 데이터 살펴보기\n","print(data.describe())\n","\n","# Descriptor에 대한 히스토그램\n","data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds']].hist(bins=30, figsize=(15, 10), layout=(2, 2));\n","\n","# 상관관계 분석\n","sns.pairplot(data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds', 'Lipophilicity']])\n","\n","# 입력 변수와 타겟 변수 분할\n","X = data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds']]\n","y = data['Lipophilicity']\n","\n","# 데이터 표준화\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# 학습 데이터와 테스트 데이터 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# MLP 모델 학습\n","model = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=500, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# 테스트 데이터에 대한 예측 수행\n","y_pred = model.predict(X_test)\n","\n","# 예측 성능 평가\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","print(\"Mean Squared Error :\", mse)\n","print(\"R^2 :\", r2)\n","\n","# 예측값 vs 실제값 분포 그래프\n","plt.figure(figsize=(8, 8))\n","plt.scatter(y_test, y_pred, c='crimson')\n","plt.yscale('log')\n","plt.xscale('log')\n","\n","p1 = max(max(y_pred), max(y_test))\n","p2 = min(min(y_pred), min(y_test))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpdqwoneIy1u"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import rdMolDescriptors\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 데이터 불러오기\n","data = pd.read_csv(\"Lipophilicity.csv\")\n","\n","# Morgan fingerprint를 계산하는 함수\n","def get_morgan_fingerprint(smiles, radius=2, nBits=1024):\n","    mol = Chem.MolFromSmiles(smiles)\n","    return rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n","\n","# Descriptor 추출\n","data['MorganFingerprint'] = data['SMILES'].apply(get_morgan_fingerprint)\n","\n","# 입력 변수와 타겟 변수 분할\n","X = np.array(list(data['MorganFingerprint']))\n","y = data['Lipophilicity']\n","\n","# 데이터 표준화\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# 학습 데이터와 테스트 데이터 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# MLP 모델 학습\n","model = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=500, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# 테스트 데이터에 대한 예측 수행\n","y_pred = model.predict(X_test)\n","\n","# 예측 성능 평가\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","print(\"Mean Squared Error :\", mse)\n","print(\"R^2 :\", r2)\n","\n","# 예측값 vs 실제값 분포 그래프\n","plt.figure(figsize=(8, 8))\n","plt.scatter(y_test, y_pred, c='crimson')\n","plt.yscale('log')\n","plt.xscale('log')\n","\n","p1 = max(max(y_pred), max(y_test))\n","p2 = min(min(y_pred), min(y_test))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJjmZaR6VloN"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import rdMolDescriptors, Descriptors\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# 데이터 불러오기\n","data = pd.read_csv(\"Lipophilicity.csv\")\n","\n","# Morgan fingerprint를 계산하는 함수\n","def get_morgan_fingerprint(smiles, radius=2, nBits=1024):\n","    mol = Chem.MolFromSmiles(smiles)\n","    return rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n","\n","# 기존 Descriptor 추출\n","data['TPSA'] = data['SMILES'].apply(lambda x: Descriptors.TPSA(Chem.MolFromSmiles(x)))\n","data['LogP'] = data['SMILES'].apply(lambda x: Descriptors.MolLogP(Chem.MolFromSmiles(x)))\n","data['MolecularWeight'] = data['SMILES'].apply(lambda x: Descriptors.MolWt(Chem.MolFromSmiles(x)))\n","data['NumRotatableBonds'] = data['SMILES'].apply(lambda x: Descriptors.NumRotatableBonds(Chem.MolFromSmiles(x)))\n","\n","# MorganFingerprint 추출\n","data['MorganFingerprint'] = data['SMILES'].apply(get_morgan_fingerprint)\n","\n","# Convert the Morgan fingerprint to a numpy array\n","data['MorganFingerprint'] = data['MorganFingerprint'].apply(lambda x: np.array(x))\n","\n","# Then, split the array into separate columns in the DataFrame\n","morgan_df = pd.DataFrame(data['MorganFingerprint'].to_list(), columns=[f'bit{i}' for i in range(1024)])\n","\n","# Now, concatenate this DataFrame with your existing one\n","X = pd.concat([data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds']], morgan_df], axis=1)\n","\n","# 데이터 표준화\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","y = data['Lipophilicity']\n","\n","# 학습 데이터와 테스트 데이터 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","\n","# MLP 모델 학습\n","model = MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=500, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# 테스트 데이터에 대한 예측 수행\n","y_pred = model.predict(X_test)\n","\n","# 예측 성능 평가\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","print(\"Mean Squared Error :\", mse)\n","print(\"R^2 :\", r2)\n","\n","# 예측값 vs 실제값 분포 그래프\n","plt.figure(figsize=(8, 8))\n","plt.scatter(y_test, y_pred, c='crimson')\n","plt.yscale('log')\n","plt.xscale('log')\n","\n","p1 = max(max(y_pred), max(y_test))\n","p2 = min(min(y_pred), min(y_test))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RcC_87Q6XeIk"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import rdMolDescriptors, Descriptors\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Model\n","from keras.layers import Dense, Input, Concatenate, Conv1D, GlobalAveragePooling1D\n","from keras.utils import plot_model\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","# 데이터 불러오기\n","data = pd.read_csv(\"Lipophilicity.csv\")\n","\n","# Morgan fingerprint를 계산하는 함수\n","def get_morgan_fingerprint(smiles, radius=2, nBits=1024):\n","    mol = Chem.MolFromSmiles(smiles)\n","    return rdMolDescriptors.GetMorganFingerprintAsBitVect(mol, radius, nBits)\n","\n","# 기존 Descriptor 추출\n","data['TPSA'] = data['SMILES'].apply(lambda x: Descriptors.TPSA(Chem.MolFromSmiles(x)))\n","data['LogP'] = data['SMILES'].apply(lambda x: Descriptors.MolLogP(Chem.MolFromSmiles(x)))\n","data['MolecularWeight'] = data['SMILES'].apply(lambda x: Descriptors.MolWt(Chem.MolFromSmiles(x)))\n","data['NumRotatableBonds'] = data['SMILES'].apply(lambda x: Descriptors.NumRotatableBonds(Chem.MolFromSmiles(x)))\n","\n","# MorganFingerprint 추출\n","data['MorganFingerprint'] = data['SMILES'].apply(get_morgan_fingerprint)\n","\n","# 입력 변수와 타겟 변수 분할\n","X_global = data[['TPSA', 'LogP', 'MolecularWeight', 'NumRotatableBonds']].values\n","X_fingerprint = np.array(list(map(list, data['MorganFingerprint'].values)))\n","y = data['Lipophilicity'].values\n","\n","# 데이터 표준화\n","scaler_global = StandardScaler()\n","X_global = scaler_global.fit_transform(X_global)\n","\n","scaler_fingerprint = StandardScaler()\n","X_fingerprint = scaler_fingerprint.fit_transform(X_fingerprint)\n","\n","# 학습 데이터와 테스트 데이터 분할\n","X_global_train, X_global_test, X_fingerprint_train, X_fingerprint_test, y_train, y_test = train_test_split(X_global, X_fingerprint, y, test_size=0.2, random_state=42)\n","\n","# 추가 차원을 만듭니다.\n","X_fingerprint_train = tf.expand_dims(X_fingerprint_train, axis=2)\n","X_fingerprint_test = tf.expand_dims(X_fingerprint_test, axis=2)\n","\n","# 모델 구성\n","input_global = Input(shape=(X_global.shape[1], ), name='global_input')\n","input_fingerprint = Input(shape=(X_fingerprint_train.shape[1], 1), name='fingerprint_input')\n","\n","conv1 = Conv1D(16, 3, activation='relu')(input_fingerprint)\n","gap1 = GlobalAveragePooling1D()(conv1)\n","\n","concat = Concatenate()([input_global, gap1])\n","\n","dense1 = Dense(64, activation='relu')(concat)\n","output = Dense(1)(dense1)\n","\n","model = Model(inputs=[input_global, input_fingerprint], outputs=output)\n","\n","# 모델 컴파일\n","model.compile(optimizer='adam', loss='mean_squared_error')\n","\n","# 모델 구조 시각화\n","plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n","\n","# 모델 학습\n","history = model.fit([X_global_train, X_fingerprint_train], y_train, validation_data=([X_global_test, X_fingerprint_test], y_test), epochs=50, batch_size=32)\n","\n","# 모델 학습 과정 시각화\n","plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], 'b-', label='loss')\n","plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n","plt.xlabel('Epoch')\n","plt.legend()\n","\n","plt.show()\n","\n","# 모델 평가\n","model.evaluate([X_global_test, X_fingerprint_test], y_test)\n","\n","from sklearn.metrics import r2_score\n","\n","# 모델 평가 2\n","loss = model.evaluate([X_global_test, X_fingerprint_test], y_test)\n","print(\"Test Loss:\", loss)\n","\n","# 예측값 계산\n","y_pred = model.predict([X_global_test, X_fingerprint_test])\n","\n","# R^2 점수 계산\n","r2 = r2_score(y_test, y_pred)\n","print(\"R^2 Score:\", r2)\n","\n","# 예측값과 실제값 비교 시각화\n","plt.figure(figsize=(5,5))\n","plt.scatter(y_test, y_pred, c='crimson')\n","plt.yscale('log')\n","plt.xscale('log')\n","\n","p1 = max(max(y_pred), max(y_test))\n","p2 = min(min(y_pred), min(y_test))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SK7rD8vecxO1"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import LSTM, Dropout, Dense, Input\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# 데이터 불러오기\n","data = pd.read_csv(\"Lipophilicity.csv\")\n","\n","# SMILES 문자열을 추출\n","smiles_list = data['SMILES'].values.tolist()\n","\n","# SMILES 문자열을 토큰화하고 정수 인코딩\n","tokenizer = Tokenizer(char_level=True)\n","tokenizer.fit_on_texts(smiles_list)\n","sequences = tokenizer.texts_to_sequences(smiles_list)\n","\n","# 시퀀스 패딩\n","max_length = max([len(seq) for seq in sequences])\n","X_smiles = pad_sequences(sequences, maxlen=max_length, padding='post')\n","\n","# SMILES 데이터를 원-핫 인코딩\n","X_smiles = to_categorical(X_smiles)\n","\n","# Lipophilicity를 타겟 변수로 설정\n","y = data['Lipophilicity'].values\n","\n","# 트레이닝셋과 테스트셋 분리\n","X_train, X_test, y_train, y_test = train_test_split(X_smiles, y, test_size=0.2, random_state=42)\n","\n","# RNN 모델 구성\n","input_layer = Input(shape=(X_train.shape[1], X_train.shape[2]))\n","lstm_layer1 = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(input_layer)\n","lstm_layer2 = LSTM(64, return_sequences=True, dropout=0.3, recurrent_dropout=0.2)(lstm_layer1)\n","lstm_layer3 = LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.2)(lstm_layer2)\n","output_layer = Dense(1, activation='linear')(lstm_layer3)\n","\n","# 모델 컴파일\n","model = Model(inputs=input_layer, outputs=output_layer)\n","model.compile(optimizer=Adam(), loss='mean_squared_error')\n","\n","# 모델 학습\n","model.fit(X_train, y_train, epochs=50, batch_size=32)\n","\n","# 테스트셋에 대한 예측 수행\n","y_pred = model.predict(X_test)\n","\n","# 예측 결과 평가 (Mean Squared Error와 R2 Score)\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","print(\"Mean Squared Error :\", mse)\n","print(\"R^2 :\", r2)\n","\n","# 실제값 대비 예측값 시각화\n","plt.figure(figsize=(8, 8))\n","plt.scatter(y_test, y_pred, c='crimson')\n","plt.yscale('log')\n","plt.xscale('log')\n","p1 = max(max(y_pred), max(y_test))\n","p2 = min(min(y_pred), min(y_test))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HqrGoVKCx-DY"},"outputs":[],"source":["!pip install torch_geometric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5U7S25Knd4yX"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import DataLoader\n","from torch.nn import Linear\n","from torch_geometric.utils import dense_to_sparse\n","from torch_geometric.data import Data\n","from rdkit import Chem\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","\n","# 데이터 불러오기\n","data = pd.read_csv('Lipophilicity.csv')\n","\n","# rdkit를 사용해 SMILES 문자열을 그래프 형태로 변환\n","# 원자와 결합의 최대 개수 설정\n","max_atoms = max([Chem.MolFromSmiles(smiles).GetNumAtoms() for smiles in data['SMILES']])\n","\n","\n","def smiles_to_graph(smiles):\n","    mol = Chem.MolFromSmiles(smiles)\n","    adj = Chem.rdmolops.GetAdjacencyMatrix(mol)\n","    features = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n","\n","    # 패딩 수행\n","    n_atoms = len(features)\n","    features.extend([0]*(max_atoms-n_atoms))\n","    adj_padding = np.zeros((max_atoms, max_atoms))\n","    adj_padding[:n_atoms, :n_atoms] = adj\n","\n","    return adj_padding, features\n","\n","graphs = [smiles_to_graph(smiles) for smiles in data['SMILES']]\n","X = [torch.tensor(features, dtype=torch.float).view(-1, 1) for _, features in graphs]\n","A = [torch.tensor(adj, dtype=torch.long) for adj, _ in graphs]\n","y = torch.tensor(data['Lipophilicity'].values, dtype=torch.float).view(-1, 1)\n","\n","class GraphDataset(Dataset):\n","    def __init__(self, X, A, y):\n","        self.X = X\n","        self.A = A\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        edge_index, _ = dense_to_sparse(self.A[idx])  # Convert adjacency matrix to edge_index\n","        return Data(x=self.X[idx], edge_index=edge_index, y=self.y[idx])\n","\n","\n","# 트레이닝셋과 테스트셋 분리\n","X_train, X_test, A_train, A_test, y_train, y_test = train_test_split(X, A, y, test_size=0.2, random_state=42)\n","train_data = GraphDataset(X_train, A_train, y_train)\n","test_data = GraphDataset(X_test, A_test, y_test)\n","\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","# 그래프 신경망(GNN) 모델 구성\n","class GNN(torch.nn.Module):\n","    def __init__(self):\n","        super(GNN, self).__init__()\n","        self.conv1 = GCNConv(1, 64)\n","        self.conv2 = GCNConv(64, 64)\n","        self.conv3 = GCNConv(64, 64)\n","        self.fc = Linear(64, 1)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.conv1(x, edge_index).relu()\n","        x = self.conv2(x, edge_index).relu()\n","        x = self.conv3(x, edge_index).relu()\n","        x = global_mean_pool(x, data.batch)\n","        x = self.fc(x)\n","        return x.view(-1)\n","\n","# 모델, 손실함수, 최적화 함수 설정\n","model = GNN()\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","print(model)\n","\n","# 학습\n","for epoch in range(100):\n","    model.train()\n","    train_losses = []\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())\n","\n","    if epoch % 10 == 0:\n","        model.eval()\n","        test_losses = []\n","        for data in test_loader:\n","            output = model(data)\n","            loss = criterion(output, data.y)\n","            test_losses.append(loss.item())\n","\n","        print(f'Epoch {epoch}:')\n","        print('Train Loss:', np.mean(train_losses))\n","        print('Test Loss:', np.mean(test_losses))\n","        model.train()\n","\n","# 평가\n","model.eval()\n","y_pred = []\n","y_true = []\n","for batch in test_loader:\n","    output = model(batch)\n","    y_pred.append(output.detach().numpy().flatten())\n","    y_true.append(batch.y.numpy().flatten())\n","\n","y_pred = np.concatenate(y_pred)\n","y_true = np.concatenate(y_true)\n","\n","print('MSE: ', mean_squared_error(y_true, y_pred))\n","print('R2 score: ', r2_score(y_true, y_pred))\n","\n","\n","# 결과 시각화\n","plt.figure(figsize=(8, 8))\n","plt.scatter(y_true, y_pred, c='crimson')\n","plt.yscale('log')\n","plt.xscale('log')\n","p1 = max(max(y_pred), max(y_true))\n","p2 = min(min(y_pred), min(y_true))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJ-QBrczx6Hd"},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import DataLoader\n","from torch.nn import Linear\n","from torch_geometric.utils import dense_to_sparse\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GATConv\n","from rdkit import Chem\n","from rdkit.Chem import rdMolDescriptors, Descriptors\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","\n","# 데이터 불러오기\n","data = pd.read_csv('Lipophilicity.csv')\n","\n","# rdkit를 사용해 SMILES 문자열을 그래프 형태로 변환\n","# 원자와 결합의 최대 개수 설정\n","max_atoms = max([Chem.MolFromSmiles(smiles).GetNumAtoms() for smiles in data['SMILES']])\n","\n","def smiles_to_graph(smiles):\n","    mol = Chem.MolFromSmiles(smiles)\n","    adj = Chem.rdmolops.GetAdjacencyMatrix(mol)\n","    features = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n","\n","    # 패딩 수행\n","    n_atoms = len(features)\n","    features.extend([0]*(max_atoms-n_atoms))\n","    adj_padding = np.zeros((max_atoms, max_atoms))\n","    adj_padding[:n_atoms, :n_atoms] = adj\n","\n","    return adj_padding, features\n","\n","graphs = [smiles_to_graph(smiles) for smiles in data['SMILES']]\n","X = [torch.tensor(features, dtype=torch.float).view(-1, 1) for _, features in graphs]\n","A = [torch.tensor(adj, dtype=torch.long) for adj, _ in graphs]\n","y = torch.tensor(data['Lipophilicity'].values, dtype=torch.float).view(-1, 1)\n","\n","# 글로벌 특성 추가\n","data['TPSA'] = data['SMILES'].apply(lambda x: Descriptors.TPSA(Chem.MolFromSmiles(x)))\n","data['LogP'] = data['SMILES'].apply(lambda x: Descriptors.MolLogP(Chem.MolFromSmiles(x)))\n","data['MolecularWeight'] = data['SMILES'].apply(lambda x: Descriptors.MolWt(Chem.MolFromSmiles(x)))\n","data['NumRotatableBonds'] = data['SMILES'].apply(lambda x: Descriptors.NumRotatableBonds(Chem.MolFromSmiles(x)))\n","\n","\n","# 글로벌 특성 데이터를 텐서로 변환\n","global_features = torch.tensor(data[['TPSA', 'LogP', 'MolecularWeight','NumRotatableBonds']].values, dtype=torch.float)\n","\n","class GraphDataset(Dataset):\n","    def __init__(self, X, A, y, global_features):\n","        self.X = X\n","        self.A = A\n","        self.y = y\n","        self.global_features = global_features\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        edge_index, _ = dense_to_sparse(self.A[idx])  # Convert adjacency matrix to edge_index\n","        return Data(x=self.X[idx], edge_index=edge_index, y=self.y[idx], global_features=self.global_features[idx].unsqueeze(0))\n","\n","\n","\n","\n","# 트레이닝셋과 테스트셋 분리\n","X_train, X_test, A_train, A_test, y_train, y_test, global_train, global_test = train_test_split(X, A, y, global_features, test_size=0.2, random_state=42)\n","train_data = GraphDataset(X_train, A_train, y_train, global_train)\n","test_data = GraphDataset(X_test, A_test, y_test, global_test)\n","\n","train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n","\n","\n","# 그래프 신경망(GAT) 모델 구성\n","class GNN(torch.nn.Module):\n","    def __init__(self):\n","        super(GNN, self).__init__()\n","        self.conv1 = GATConv(1, 64)\n","        self.conv2 = GATConv(64, 64)\n","        self.conv3 = GATConv(64, 64)\n","        self.global_feature_layer = Linear(4, 64)  # 추가: global feature layer\n","        self.fc = Linear(128, 1)\n","\n","    def forward(self, data):\n","        x, edge_index, global_features = data.x, data.edge_index, data.global_features  # 수정\n","        x = self.conv1(x, edge_index).relu()\n","        x = self.conv2(x, edge_index).relu()\n","        x = self.conv3(x, edge_index).relu()\n","        x = global_mean_pool(x, data.batch)\n","        global_features = self.global_feature_layer(global_features).relu()  # 추가: global feature 처리\n","\n","        x = torch.cat([x, global_features], dim=1)  # 수정: local feature와 global feature 결합\n","        x = self.fc(x)\n","        return x.view(-1)\n","\n","# 모델, 손실함수, 최적화 함수 설정\n","model = GNN()\n","criterion = nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","print(model)\n","\n","\n","\n","# 학습\n","for epoch in range(30):\n","    model.train()\n","    train_losses = []\n","    for data in train_loader:\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, data.y)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())\n","\n","    if epoch % 10 == 0:\n","        model.eval()\n","        test_losses = []\n","        for data in test_loader:\n","            output = model(data)\n","            loss = criterion(output, data.y)\n","            test_losses.append(loss.item())\n","\n","        print(f'Epoch {epoch}:')\n","        print('Train Loss:', np.mean(train_losses))\n","        print('Test Loss:', np.mean(test_losses))\n","        model.train()\n","\n","# 평가\n","model.eval()\n","y_pred = []\n","y_true = []\n","for batch in test_loader:\n","    output = model(batch)\n","    y_pred.append(output.detach().numpy().flatten())\n","    y_true.append(batch.y.numpy().flatten())\n","\n","y_pred = np.concatenate(y_pred)\n","y_true = np.concatenate(y_true)\n","\n","print('MSE: ', mean_squared_error(y_true, y_pred))\n","print('R2 score: ', r2_score(y_true, y_pred))\n","\n","\n","# 결과 시각화\n","plt.figure(figsize=(8, 8))\n","plt.scatter(y_test, y_pred, c='crimson')\n","plt.yscale('log')\n","plt.xscale('log')\n","p1 = max(max(y_pred), max(y_test))\n","p2 = min(min(y_pred), min(y_test))\n","plt.plot([p1, p2], [p1, p2], 'b-')\n","plt.xlabel('True Values', fontsize=15)\n","plt.ylabel('Predictions', fontsize=15)\n","plt.axis('equal')\n","plt.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"lFTqXxoi45lq"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
